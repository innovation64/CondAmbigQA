# ![CondAmbigQA](https://your-banner-image-url.png)

ğŸ  [Homepage](https://github.com/innovation64/CondAmbigQA) | ğŸ“ [Paper](https://arxiv.org/abs/2502.01523) | ğŸ¤— [Dataset](https://huggingface.co/datasets/Apocalypse-AGI-DAO/CondAmbigQA) | ğŸ“Š [Results](#results) | ğŸŒ [ä¸­æ–‡](./README_zh.md)

ğŸ”„ Supported by RAG, LLMs, Conditions-based QA

ğŸ’« A novel benchmark for resolving ambiguous questions through conditions identification.

## ğŸ“Œ CondAmbigQA: A Conditional Ambiguous Question Answering Benchmark

- ğŸ“š News
  - ğŸ‰ Dataset Release: [Hugging Face](https://huggingface.co/datasets/Apocalypse-AGI-DAO/CondAmbigQA)
  - ğŸ“„ Paper Release: [arXiv](https://arxiv.org/abs/2502.01523)

- ğŸš€ Getting Started
  - [Installation](#installation)
  - [Dataset Usage](#dataset-usage)
  - [Model Evaluation](#evaluation)

## ğŸ’¡ Quick Start

```python
from datasets import load_dataset
dataset = load_dataset("Apocalypse-AGI-DAO/CondAmbigQA")
```

## ğŸ“Š Results 

| Model | Condition Score | Answer Score | Citation Score |
|-------|----------------|--------------|----------------|
| LLaMA3.1 | 0.305 | 0.276 | 0.058 |
| Mistral | 0.316 | 0.272 | 0.036 |
| Qwen2.5 | 0.317 | 0.297 | 0.050 |
| GLM4 | 0.313 | 0.295 | 0.059 |
| Gemma2 | 0.309 | 0.306 | 0.077 |

## ğŸ“– Citation

```bibtex
@article{li2024condambigqa,
  title={CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering},
  author={Li, Zongxi and Li, Yang and Xie, Haoran and Qin, S. Joe},
  journal={arXiv preprint arXiv:2502.01523},
  year={2024}
}
```

## ğŸ“¬ Contact 

- Email: zongxili@ln.edu.hk
- Join our community: [Discord](#) | [Slack](#) | [WeChat](#)
